{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBlYyt7aVJHi",
        "outputId": "9df54d7b-5b79-4263-e3d4-d7abaf93391a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.14.0\n",
            "Uninstalling tensorflow-2.14.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.14.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.14.0\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.59.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.20)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.42.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.11.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "Successfully installed gast-0.4.0 keras-2.12.0 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"
          ]
        }
      ],
      "source": [
        "! pip uninstall tensorflow\n",
        "! pip install tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "4D8WQakOVT2a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('Football 49 Data_Season 2023.csv')\n",
        "\n",
        "# Selecting relevant features for the LSTM model\n",
        "selected_features = ['Play Number', 'Series', 'Down', 'Distance', 'Field Position', 'Gain',\n",
        "                     'Formation', 'Motion', 'Play', 'Run Concept', 'The_Play',\n",
        "                     'R/P', 'Pass Result']"
      ],
      "metadata": {
        "id": "STSkUoMhVT_3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding lagged features for 'QB Comment'\n",
        "num_lags = 5\n",
        "for lag in range(1, num_lags + 1):\n",
        "    data[f'QB_Comment_lag_{lag}'] = data['QB Comment'].shift(lag)"
      ],
      "metadata": {
        "id": "yWu1kcOZVUCI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping rows with NaN values created due to lagging\n",
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "26zuEzzCVUET"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical variables\n",
        "categorical_columns = data[selected_features].select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "FlviQIwFVUGk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing numerical features\n",
        "numerical_columns = data[selected_features].select_dtypes(include=['float64', 'int64']).columns\n",
        "scaler = MinMaxScaler()\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])"
      ],
      "metadata": {
        "id": "HgkdawTjVUJN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the target variable (QB Comment) and encoding it\n",
        "target_variable = 'QB Comment'\n",
        "le_target = LabelEncoder()\n",
        "data[target_variable] = le_target.fit_transform(data[target_variable])"
      ],
      "metadata": {
        "id": "dZb_T1GSVULb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into main and hold-out sets\n",
        "main_data, holdout_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "KV0wgExBVUPB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Further split the main dataset into training, validation, and test sets\n",
        "split_index_1 = int(len(main_data) * 0.6)  # 60% for training\n",
        "split_index_2 = int(len(main_data) * 0.8)  # Next 20% for validation, remaining for testing"
      ],
      "metadata": {
        "id": "46Sjx4V3Vn-h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = main_data[:split_index_1]\n",
        "validation_data = main_data[split_index_1:split_index_2]\n",
        "test_data = main_data[split_index_2:]\n"
      ],
      "metadata": {
        "id": "o_qRb9txVoA1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and target for each set\n",
        "X_train, y_train = train_data[selected_features].values, train_data[target_variable].values\n",
        "X_validation, y_validation = validation_data[selected_features].values, validation_data[target_variable].values\n",
        "X_test, y_test = test_data[selected_features].values, test_data[target_variable].values\n",
        "X_holdout, y_holdout = holdout_data[selected_features].values, holdout_data[target_variable].values\n"
      ],
      "metadata": {
        "id": "-ht8ZwZoVoDN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the window size for the LSTM model\n",
        "window_size = 5  # Using 5 previous time steps to predict the next one"
      ],
      "metadata": {
        "id": "NnGJ6kzhVoFX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create time series generators for each dataset\n",
        "train_generator = TimeseriesGenerator(X_train, y_train, length=window_size, batch_size=1)\n",
        "validation_generator = TimeseriesGenerator(X_validation, y_validation, length=window_size, batch_size=1)\n",
        "test_generator = TimeseriesGenerator(X_test, y_test, length=window_size, batch_size=1)\n",
        "holdout_generator = TimeseriesGenerator(X_holdout, y_holdout, length=window_size, batch_size=1)"
      ],
      "metadata": {
        "id": "LpMmLo7FVoHs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create the LSTM model\n",
        "def create_lstm_model(lstm_units=50, dropout_rate=0.2, optimizer='adam'):\n",
        "    model = Sequential([\n",
        "        LSTM(lstm_units, activation='relu', input_shape=(window_size, X_train.shape[1])),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(units=len(np.unique(y_train)), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "vEWZUx8zVoJ5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter options\n",
        "lstm_units_options = [50, 100]\n",
        "dropout_rate_options = [0.0, 0.2, 0.5]\n",
        "optimizer_options = ['adam', 'rmsprop']\n",
        "\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "\n",
        "for lstm_units in lstm_units_options:\n",
        "    for dropout_rate in dropout_rate_options:\n",
        "        for optimizer in optimizer_options:\n",
        "            # K-Fold Cross Validation\n",
        "            kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "            cv_scores = []\n",
        "\n",
        "            for train, val in kfold.split(X_train, y_train):\n",
        "                model = create_lstm_model(lstm_units, dropout_rate, optimizer)\n",
        "\n",
        "                # Create generators for each fold\n",
        "                train_gen = TimeseriesGenerator(X_train[train], y_train[train], length=window_size, batch_size=1)\n",
        "                val_gen = TimeseriesGenerator(X_train[val], y_train[val], length=window_size, batch_size=1)\n",
        "\n",
        "                # Train the model\n",
        "                model.fit(train_gen, epochs=10)\n",
        "\n",
        "                # Evaluate the model\n",
        "                scores = model.evaluate(val_gen, verbose=0)\n",
        "                cv_scores.append(scores[1])  # Assuming 1 is the index for accuracy\n",
        "\n",
        "            # Average CV score for this hyperparameter combo\n",
        "            avg_cv_score = np.mean(cv_scores)\n",
        "\n",
        "            if avg_cv_score > best_score:\n",
        "                best_score = avg_cv_score\n",
        "                best_params = {'lstm_units': lstm_units, 'dropout_rate': dropout_rate, 'optimizer': optimizer}\n",
        "\n",
        "print(f'Best score: {best_score}, Best parameters: {best_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E4Yu3b8VoL-",
        "outputId": "fa66ed2c-d66b-4d42-d389-a889c71296d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "243/243 [==============================] - 4s 7ms/step - loss: 1.9978 - accuracy: 0.3704\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8055 - accuracy: 0.4033\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7956 - accuracy: 0.4033\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7829 - accuracy: 0.4033\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7667 - accuracy: 0.4033\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7561 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7332 - accuracy: 0.4074\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7197 - accuracy: 0.3992\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6927 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.6732 - accuracy: 0.3951\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.9758 - accuracy: 0.3663\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8625 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8555 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8452 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8409 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8177 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8132 - accuracy: 0.3663\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7892 - accuracy: 0.3745\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7601 - accuracy: 0.3745\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7751 - accuracy: 0.3786\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.9216 - accuracy: 0.3909\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7596 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7568 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7381 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7383 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7322 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7140 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6949 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6782 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6622 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9030 - accuracy: 0.3992\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7960 - accuracy: 0.3992\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7954 - accuracy: 0.4033\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7998 - accuracy: 0.4033\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7835 - accuracy: 0.4033\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7771 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7692 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7563 - accuracy: 0.4033\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7527 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7454 - accuracy: 0.4033\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 4ms/step - loss: 1.9652 - accuracy: 0.3210\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8839 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8644 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8588 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8540 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8403 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8423 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8372 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8272 - accuracy: 0.3704\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8194 - accuracy: 0.3704\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 2s 5ms/step - loss: 1.8974 - accuracy: 0.3909\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7795 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7693 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7541 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7350 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7290 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7165 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6946 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6988 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6871 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.9370 - accuracy: 0.3580\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8064 - accuracy: 0.4115\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8027 - accuracy: 0.3992\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8132 - accuracy: 0.3951\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7928 - accuracy: 0.4156\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7803 - accuracy: 0.4115\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7385 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7635 - accuracy: 0.3951\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7526 - accuracy: 0.4115\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7404 - accuracy: 0.4074\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.9896 - accuracy: 0.3498\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8548 - accuracy: 0.3663\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8634 - accuracy: 0.3621\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8662 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8614 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8197 - accuracy: 0.3745\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8417 - accuracy: 0.3663\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8163 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8164 - accuracy: 0.3663\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7947 - accuracy: 0.3663\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.8575 - accuracy: 0.4198\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7878 - accuracy: 0.4239\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7500 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7698 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7475 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7369 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7110 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7156 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6945 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6742 - accuracy: 0.4280\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9423 - accuracy: 0.3704\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8338 - accuracy: 0.3827\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8035 - accuracy: 0.3992\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7992 - accuracy: 0.4033\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7906 - accuracy: 0.3992\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7879 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7941 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7719 - accuracy: 0.4033\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7542 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7650 - accuracy: 0.4033\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 2s 5ms/step - loss: 2.0581 - accuracy: 0.2963\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8817 - accuracy: 0.3663\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8824 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8755 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8807 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8726 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8421 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8789 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8579 - accuracy: 0.3704\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8346 - accuracy: 0.3704\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 2s 5ms/step - loss: 1.9397 - accuracy: 0.3992\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7904 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7659 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7470 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7725 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7358 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7096 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7190 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7066 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.6968 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.9868 - accuracy: 0.3827\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8882 - accuracy: 0.3580\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8350 - accuracy: 0.3992\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8364 - accuracy: 0.3745\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8005 - accuracy: 0.4033\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8151 - accuracy: 0.3951\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7891 - accuracy: 0.4074\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8110 - accuracy: 0.4074\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8106 - accuracy: 0.4115\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7662 - accuracy: 0.4074\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 4s 6ms/step - loss: 2.0214 - accuracy: 0.3580\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.9526 - accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.9303 - accuracy: 0.3416\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8946 - accuracy: 0.3663\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8662 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8796 - accuracy: 0.3457\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8645 - accuracy: 0.3786\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8801 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 3s 13ms/step - loss: 1.8673 - accuracy: 0.3745\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8493 - accuracy: 0.3539\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 2.0005 - accuracy: 0.4033\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8354 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8298 - accuracy: 0.4074\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7847 - accuracy: 0.4156\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7844 - accuracy: 0.4156\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7704 - accuracy: 0.4156\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7522 - accuracy: 0.4115\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7276 - accuracy: 0.4321\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7227 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7166 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 2.0596 - accuracy: 0.2963\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8611 - accuracy: 0.3909\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8586 - accuracy: 0.3868\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8202 - accuracy: 0.3868\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7994 - accuracy: 0.3992\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8177 - accuracy: 0.3992\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7955 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7656 - accuracy: 0.4033\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7768 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8135 - accuracy: 0.4033\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 2.0816 - accuracy: 0.3169\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.9463 - accuracy: 0.3621\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8901 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8984 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8873 - accuracy: 0.3745\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8664 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.9006 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8731 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8649 - accuracy: 0.3704\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8664 - accuracy: 0.3704\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 7ms/step - loss: 1.9303 - accuracy: 0.3909\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8360 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7611 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8149 - accuracy: 0.4239\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7887 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7514 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7446 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7466 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7459 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7238 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.8970 - accuracy: 0.3621\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8260 - accuracy: 0.4033\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7923 - accuracy: 0.4033\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7769 - accuracy: 0.4033\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7868 - accuracy: 0.4033\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7649 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7531 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7525 - accuracy: 0.3992\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7231 - accuracy: 0.3992\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7054 - accuracy: 0.4033\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 5ms/step - loss: 1.9864 - accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8843 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8618 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8646 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8477 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8409 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8332 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.8205 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7900 - accuracy: 0.3621\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7763 - accuracy: 0.3745\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 5s 6ms/step - loss: 1.8725 - accuracy: 0.4033\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7697 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7536 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7255 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 9ms/step - loss: 1.7291 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7056 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7160 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.6758 - accuracy: 0.4156\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.6706 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.6279 - accuracy: 0.4321\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.8876 - accuracy: 0.3786\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8025 - accuracy: 0.4033\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8057 - accuracy: 0.3992\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7983 - accuracy: 0.4033\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7856 - accuracy: 0.4033\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7868 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7724 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7687 - accuracy: 0.4033\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7452 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7384 - accuracy: 0.4074\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 7ms/step - loss: 1.9595 - accuracy: 0.3374\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8719 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8766 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8638 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8601 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8579 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8344 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8298 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8272 - accuracy: 0.3704\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8198 - accuracy: 0.3704\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.8676 - accuracy: 0.3992\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7907 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7563 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7419 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7360 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7214 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7127 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.6972 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.6939 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.6719 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9449 - accuracy: 0.3992\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8002 - accuracy: 0.4074\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8091 - accuracy: 0.4033\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8182 - accuracy: 0.3992\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7788 - accuracy: 0.3992\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7786 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7664 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7597 - accuracy: 0.4033\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7786 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 1.7344 - accuracy: 0.4115\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 4s 7ms/step - loss: 1.9670 - accuracy: 0.3621\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8763 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8697 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8740 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8524 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 9ms/step - loss: 1.8461 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8411 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8201 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8169 - accuracy: 0.3704\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7843 - accuracy: 0.3663\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.8648 - accuracy: 0.3992\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7788 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7780 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7705 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7277 - accuracy: 0.4239\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7357 - accuracy: 0.4156\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7133 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.6921 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.6854 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.6658 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9196 - accuracy: 0.3827\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8161 - accuracy: 0.4033\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8160 - accuracy: 0.3992\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8066 - accuracy: 0.4033\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7955 - accuracy: 0.4033\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7757 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7862 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7667 - accuracy: 0.4033\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7668 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7604 - accuracy: 0.4033\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 5s 7ms/step - loss: 1.9768 - accuracy: 0.3663\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8846 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8782 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8710 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8639 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8673 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8305 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8485 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8372 - accuracy: 0.3704\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8112 - accuracy: 0.3704\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 4s 8ms/step - loss: 1.8658 - accuracy: 0.3951\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7885 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7748 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7545 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7496 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7264 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7287 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.6976 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.6858 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.6945 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9692 - accuracy: 0.3704\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 9ms/step - loss: 1.8230 - accuracy: 0.3992\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8298 - accuracy: 0.3951\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8313 - accuracy: 0.3992\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8290 - accuracy: 0.3909\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8166 - accuracy: 0.3868\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7716 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7514 - accuracy: 0.3992\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7890 - accuracy: 0.3992\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7927 - accuracy: 0.3992\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 2.0484 - accuracy: 0.3539\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8971 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8747 - accuracy: 0.3580\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.9063 - accuracy: 0.3663\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8481 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8767 - accuracy: 0.3416\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8878 - accuracy: 0.3663\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8507 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8321 - accuracy: 0.3745\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8318 - accuracy: 0.3704\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9782 - accuracy: 0.3868\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8025 - accuracy: 0.4074\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7870 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7760 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7483 - accuracy: 0.4074\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7332 - accuracy: 0.4362\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7594 - accuracy: 0.4156\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7275 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7202 - accuracy: 0.4156\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.6873 - accuracy: 0.4198\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9349 - accuracy: 0.3663\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8507 - accuracy: 0.3704\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8446 - accuracy: 0.3992\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.8085 - accuracy: 0.4115\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8301 - accuracy: 0.3951\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8039 - accuracy: 0.4033\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7826 - accuracy: 0.4033\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7999 - accuracy: 0.4033\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.7463 - accuracy: 0.4033\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7784 - accuracy: 0.4033\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 6ms/step - loss: 1.9969 - accuracy: 0.3539\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.9318 - accuracy: 0.3580\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.9049 - accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8924 - accuracy: 0.3704\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 2s 6ms/step - loss: 1.8802 - accuracy: 0.3704\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.8730 - accuracy: 0.3704\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8750 - accuracy: 0.3704\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8556 - accuracy: 0.3704\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8511 - accuracy: 0.3704\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.8297 - accuracy: 0.3704\n",
            "Epoch 1/10\n",
            "243/243 [==============================] - 3s 8ms/step - loss: 1.8997 - accuracy: 0.3951\n",
            "Epoch 2/10\n",
            "243/243 [==============================] - 2s 8ms/step - loss: 1.7911 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7969 - accuracy: 0.4198\n",
            "Epoch 4/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7741 - accuracy: 0.4198\n",
            "Epoch 5/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7849 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7628 - accuracy: 0.4198\n",
            "Epoch 7/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7557 - accuracy: 0.4198\n",
            "Epoch 8/10\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 1.7488 - accuracy: 0.4198\n",
            "Epoch 9/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7184 - accuracy: 0.4198\n",
            "Epoch 10/10\n",
            "243/243 [==============================] - 1s 6ms/step - loss: 1.7185 - accuracy: 0.4198\n",
            "Best score: 0.3977591097354889, Best parameters: {'lstm_units': 50, 'dropout_rate': 0.0, 'optimizer': 'adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the model with the best hyperparameters\n",
        "best_lstm_units = best_params['lstm_units']\n",
        "best_dropout_rate = best_params['dropout_rate']\n",
        "best_optimizer = best_params['optimizer']"
      ],
      "metadata": {
        "id": "QhjWivxfVoOd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_lstm_model(lstm_units=best_lstm_units, dropout_rate=best_dropout_rate, optimizer=best_optimizer)\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "model.fit(train_generator, epochs=10, validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9R1eYB0V7-s",
        "outputId": "4ea6356c-1faa-42ca-d4ab-8fbbb84e3963"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "367/367 [==============================] - 6s 7ms/step - loss: 1.9207 - accuracy: 0.3651 - val_loss: 1.9264 - val_accuracy: 0.3613\n",
            "Epoch 2/10\n",
            "367/367 [==============================] - 2s 6ms/step - loss: 1.8121 - accuracy: 0.3978 - val_loss: 1.9106 - val_accuracy: 0.3613\n",
            "Epoch 3/10\n",
            "367/367 [==============================] - 2s 6ms/step - loss: 1.8015 - accuracy: 0.3978 - val_loss: 1.9460 - val_accuracy: 0.3613\n",
            "Epoch 4/10\n",
            "367/367 [==============================] - 2s 6ms/step - loss: 1.7864 - accuracy: 0.3978 - val_loss: 1.9230 - val_accuracy: 0.3613\n",
            "Epoch 5/10\n",
            "367/367 [==============================] - 4s 10ms/step - loss: 1.7862 - accuracy: 0.3978 - val_loss: 1.9267 - val_accuracy: 0.3613\n",
            "Epoch 6/10\n",
            "367/367 [==============================] - 2s 6ms/step - loss: 1.7770 - accuracy: 0.3978 - val_loss: 1.8960 - val_accuracy: 0.3613\n",
            "Epoch 7/10\n",
            "367/367 [==============================] - 2s 6ms/step - loss: 1.7703 - accuracy: 0.3978 - val_loss: 1.9047 - val_accuracy: 0.3613\n",
            "Epoch 8/10\n",
            "367/367 [==============================] - 2s 6ms/step - loss: 1.7542 - accuracy: 0.3978 - val_loss: 1.9354 - val_accuracy: 0.3613\n",
            "Epoch 9/10\n",
            "367/367 [==============================] - 3s 8ms/step - loss: 1.7262 - accuracy: 0.3978 - val_loss: 1.9262 - val_accuracy: 0.3613\n",
            "Epoch 10/10\n",
            "367/367 [==============================] - 2s 6ms/step - loss: 1.7149 - accuracy: 0.3978 - val_loss: 1.9368 - val_accuracy: 0.3613\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7af2c7a6d420>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW_CZBgEV8BD",
        "outputId": "4a56ae6e-549f-4353-d2a9-483208c2d043"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_36 (LSTM)              (None, 50)                12800     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 50)                0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,310\n",
            "Trainable params: 13,310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training, validation, test, and hold-out sets\n",
        "print('Training Set Evaluation:', model.evaluate(train_generator))\n",
        "print('Validation Set Evaluation:', model.evaluate(validation_generator))\n",
        "print('Test Set Evaluation:', model.evaluate(test_generator))\n",
        "print('Holdout Set Evaluation:', model.evaluate(holdout_generator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CitH0_p-V8EY",
        "outputId": "b5c66d03-0edf-4a87-dcda-735b97f53992"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "367/367 [==============================] - 1s 3ms/step - loss: 1.6927 - accuracy: 0.3978\n",
            "Training Set Evaluation: [1.692723035812378, 0.3978201746940613]\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 1.9368 - accuracy: 0.3613\n",
            "Validation Set Evaluation: [1.936793327331543, 0.3613445460796356]\n",
            "119/119 [==============================] - 0s 3ms/step - loss: 1.9109 - accuracy: 0.3866\n",
            "Test Set Evaluation: [1.9108823537826538, 0.38655462861061096]\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 1.8274 - accuracy: 0.4133\n",
            "Holdout Set Evaluation: [1.827436089515686, 0.41333332657814026]\n"
          ]
        }
      ]
    }
  ]
}